{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia Distributed Computing Tutorial\n",
    "\n",
    "This tutorial demonstrates the basics of distributed computing in Julia, including:\n",
    "\n",
    "1. **Serial computation** (baseline for comparison)\n",
    "2. **Simple distributed computation** using `@distributed` macro  \n",
    "3. **Advanced distributed computation** with explicit chunking\n",
    "4. **Performance comparison** and scalability analysis\n",
    "5. **Best practices** for distributed computing\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "**Distributed Computing vs Multithreading:**\n",
    "- **Processes** have separate memory spaces (no shared memory)\n",
    "- **Communication** happens via message passing\n",
    "- **Scalability** can extend across multiple machines in a cluster  \n",
    "- **Overhead** is higher but provides better isolation and fault tolerance\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will understand:\n",
    "- When to use distributed computing vs multithreading\n",
    "- How to implement distributed algorithms in Julia\n",
    "- Performance trade-offs and optimization strategies\n",
    "- Best practices for distributed system design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "println(\"Active project: $(Pkg.project().path)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "using Statistics\n",
    "using BenchmarkTools  # For performance benchmarking\n",
    "\n",
    "# Display system information\n",
    "println(\"Julia Distributed Computing Tutorial\")\n",
    "println(\"=\" ^ 45)\n",
    "println(\"Available CPU cores: $(Sys.CPU_THREADS)\")\n",
    "println(\"Current Julia processes: $(nprocs())\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add worker processes (automatically detects available cores)\n",
    "println(\"\\nAdding worker processes...\")\n",
    "\n",
    "# We are adding 10 additional processes\n",
    "addprocs(10)\n",
    "\n",
    "println(\"Main process ID: $(myid())\")\n",
    "println(\"Worker process IDs: $(workers())\")\n",
    "println(\"Total processes: $(nprocs())\")\n",
    "println(\"✓ Distributed environment ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages on all worker processes\n",
    "@everywhere begin\n",
    "    using Statistics\n",
    "    using BenchmarkTools\n",
    "end\n",
    "\n",
    "println(\"\\n✓ Packages loaded on all worker processes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin\n",
    "    \"\"\"\n",
    "        simulate_heavy_compute(t::Float64)::Nothing\n",
    "\n",
    "    Simulates a computationally expensive operation by sleeping for `t` seconds.\n",
    "    This represents any CPU-intensive task like numerical computation, simulation, etc.\n",
    "    \n",
    "    # Arguments\n",
    "    - `t::Float64`: Sleep duration in seconds\n",
    "\n",
    "    # Example\n",
    "    ```julia\n",
    "    simulate_heavy_compute(0.1)  # Simulates 0.1 seconds of work\n",
    "    ```\n",
    "    \"\"\"\n",
    "    function simulate_heavy_compute(t::Float64)::Nothing\n",
    "        sleep(t)\n",
    "        return nothing\n",
    "    end\n",
    "\n",
    "    \"\"\"\n",
    "        create_line(x::Float64)::Float64\n",
    "\n",
    "    A simple linear function that computes `1.0 * x + 2.0`.\n",
    "    This represents a deterministic computation that we can verify for correctness.\n",
    "\n",
    "    # Arguments\n",
    "    - `x::Float64`: Input value\n",
    "\n",
    "    # Returns\n",
    "    - `Float64`: Linear transformation of input\n",
    "    \"\"\"\n",
    "    function create_line(x::Float64)::Float64\n",
    "        return 1.0 * x + 2.0\n",
    "    end\n",
    "\n",
    "    \"\"\"\n",
    "        qoi(x::Float64)::Float64\n",
    "\n",
    "    Computes the \"Quantity of Interest\" (QoI) for a given input.\n",
    "    Combines simulated heavy computation with a deterministic calculation.\n",
    "    This represents a typical scientific computing workload.\n",
    "    \"\"\"\n",
    "    function qoi(x::Float64)::Float64\n",
    "        simulate_heavy_compute(0.01)  # Reduced time for faster demo\n",
    "        return create_line(x)\n",
    "    end\n",
    "\n",
    "    \"\"\"\n",
    "        sum_serial(xarr::AbstractVector)::Float64\n",
    "\n",
    "    **SERIAL COMPUTATION (Single-process baseline)**\n",
    "\n",
    "    Computes the sum of QoI for all elements using a single process.\n",
    "    This serves as our baseline for performance comparison.\n",
    "\n",
    "    # Performance Characteristics\n",
    "    - Uses only one process (and one CPU core)\n",
    "    - Predictable, deterministic execution\n",
    "    - No inter-process communication overhead\n",
    "    \"\"\"\n",
    "    function sum_serial(xarr::AbstractVector)::Float64\n",
    "        y_serial = 0.0\n",
    "        for x in xarr\n",
    "            y_serial += qoi(x)\n",
    "        end\n",
    "        return y_serial\n",
    "    end\n",
    "\n",
    "    \"\"\"\n",
    "        process_chunk(chunk_indices::UnitRange{Int}, xarr::AbstractVector)::Float64\n",
    "\n",
    "    **HELPER FUNCTION: Process a chunk of data**\n",
    "\n",
    "    Processes a specific range of indices from the input array.\n",
    "    This function runs on worker processes in the distributed computation.\n",
    "    \"\"\"\n",
    "    function process_chunk(chunk_indices::UnitRange{Int}, xarr::AbstractVector)::Float64\n",
    "        chunk_sum = 0.0\n",
    "        for i in chunk_indices\n",
    "            chunk_sum += qoi(xarr[i])\n",
    "        end\n",
    "        return chunk_sum\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"✓ Core functions loaded on all worker processes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    sum_distributed_simple(xarr::AbstractVector)::Float64\n",
    "\n",
    "**DISTRIBUTED COMPUTATION (Simple approach)**\n",
    "\n",
    "Computes the sum of QoI using Julia's `@distributed` macro.\n",
    "This is the simplest way to distribute computation across processes.\n",
    "\n",
    "# How it works\n",
    "1. `@distributed (+)` automatically distributes loop iterations across workers\n",
    "2. Each worker processes a subset of the array elements\n",
    "3. Results are automatically combined using the `+` operation\n",
    "4. Communication and synchronization are handled automatically\n",
    "\n",
    "# Advantages\n",
    "- Very simple to implement\n",
    "- Automatic load balancing\n",
    "- Built-in result aggregation\n",
    "\n",
    "# Disadvantages  \n",
    "- Less control over work distribution\n",
    "- May have higher communication overhead for small chunks\n",
    "\"\"\"\n",
    "function sum_distributed_simple(xarr::AbstractVector)::Float64\n",
    "    result = @distributed (+) for x in xarr\n",
    "        qoi(x)\n",
    "    end\n",
    "    return result\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    sum_distributed_chunked(xarr::AbstractVector)::Float64\n",
    "\n",
    "**DISTRIBUTED COMPUTATION (Chunked approach)**\n",
    "\n",
    "Computes the sum of QoI using explicit work distribution with larger chunks.\n",
    "This approach provides more control over how work is divided among processes.\n",
    "\n",
    "# How it works\n",
    "1. Divide the array indices into chunks, one per worker process\n",
    "2. Use `pmap` to apply `process_chunk` function to each chunk in parallel\n",
    "3. Each worker processes its entire chunk locally (reducing communication)\n",
    "4. Combine results from all workers\n",
    "\n",
    "# Advantages\n",
    "- Better control over work distribution  \n",
    "- Lower communication overhead (fewer, larger messages)\n",
    "- More efficient for large arrays\n",
    "\n",
    "# Disadvantages\n",
    "- Slightly more complex to implement\n",
    "- Manual load balancing required\n",
    "\"\"\"\n",
    "function sum_distributed_chunked(xarr::AbstractVector)::Float64\n",
    "    # Handle edge case: if fewer elements than processes, use serial computation\n",
    "    if length(xarr) < nprocs()\n",
    "        return sum_serial(xarr)\n",
    "    end\n",
    "    \n",
    "    # Split the array indices into chunks for each worker process\n",
    "    chunks = Distributed.splitrange(1, length(xarr), nprocs())\n",
    "    \n",
    "    # Use pmap to distribute chunk processing across workers\n",
    "    chunk_results = pmap(chunk -> process_chunk(chunk, xarr), chunks)\n",
    "    \n",
    "    # Sum up results from all chunks\n",
    "    return sum(chunk_results)\n",
    "end\n",
    "\n",
    "println(\"✓ Distributed functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PERFORMANCE COMPARISON DEMONSTRATION\n",
    "# =============================================================================\n",
    "\n",
    "# Create test data\n",
    "println(\"\\n\" * \"=\" ^ 50)\n",
    "println(\"PERFORMANCE COMPARISON DEMONSTRATION\")  \n",
    "println(\"=\" ^ 50)\n",
    "\n",
    "println(\"Setting up test data...\")\n",
    "xarr = range(1.0, 100.0, length=100)  # Moderate size for notebook demo\n",
    "println(\"Array size: $(length(xarr)) elements\")\n",
    "println(\"Expected result: $(sum(create_line.(xarr)))\")\n",
    "\n",
    "# Pre-compile functions (important for accurate benchmarking)\n",
    "println(\"\\nPre-compiling functions...\")\n",
    "_ = sum_serial(xarr[1:5])\n",
    "_ = sum_distributed_simple(xarr[1:5])  \n",
    "_ = sum_distributed_chunked(xarr[1:5])\n",
    "println(\"✓ Functions compiled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. SERIAL COMPUTATION (Baseline)\n",
    "# =============================================================================\n",
    "println(\"\\n1. SERIAL COMPUTATION\")\n",
    "println(\"-\" ^ 30)\n",
    "print(\"Running serial computation... \")\n",
    "serial_result = @timed sum_serial(xarr)\n",
    "println(\"✓ Complete\")\n",
    "println(\"Result: $(serial_result.value)\")\n",
    "println(\"Time: $(round(serial_result.time, digits=3)) seconds\")\n",
    "println(\"Memory: $(serial_result.bytes) bytes\")\n",
    "println(\"Process: Main process only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. DISTRIBUTED COMPUTATION (Simple @distributed)\n",
    "# =============================================================================\n",
    "println(\"\\n2. DISTRIBUTED COMPUTATION (Simple)\")\n",
    "println(\"-\" ^ 40)\n",
    "println(\"✅ Using @distributed macro for automatic distribution\")\n",
    "\n",
    "# Run multiple times to show consistency\n",
    "simple_results = Float64[]\n",
    "simple_times = Float64[]\n",
    "\n",
    "for i in 1:3\n",
    "    print(\"Run $i... \")\n",
    "    result = @timed sum_distributed_simple(xarr)\n",
    "    push!(simple_results, result.value)\n",
    "    push!(simple_times, result.time)\n",
    "    println(\"Result: $(result.value), Time: $(round(result.time, digits=3))s\")\n",
    "end\n",
    "\n",
    "println(\"Results consistency: $(length(unique(simple_results)) == 1 ? \"✓ Consistent\" : \"✗ Inconsistent\")\")\n",
    "println(\"Average time: $(round(mean(simple_times), digits=3)) seconds\")\n",
    "println(\"Processes used: Main + $(length(workers())) workers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. DISTRIBUTED COMPUTATION (Chunked approach)\n",
    "# =============================================================================\n",
    "println(\"\\n3. DISTRIBUTED COMPUTATION (Chunked)\")\n",
    "println(\"-\" ^ 40)\n",
    "println(\"✅ Using explicit chunking with pmap for better control\")\n",
    "\n",
    "# Run multiple times to show consistency\n",
    "chunked_results = Float64[]\n",
    "chunked_times = Float64[]\n",
    "\n",
    "for i in 1:3\n",
    "    print(\"Run $i... \")\n",
    "    result = @timed sum_distributed_chunked(xarr)\n",
    "    push!(chunked_results, result.value)\n",
    "    push!(chunked_times, result.time)\n",
    "    println(\"Result: $(result.value), Time: $(round(result.time, digits=3))s\")\n",
    "end\n",
    "\n",
    "println(\"Results consistency: $(length(unique(chunked_results)) == 1 ? \"✓ Consistent\" : \"✗ Inconsistent\")\")\n",
    "println(\"Average time: $(round(mean(chunked_times), digits=3)) seconds\")\n",
    "println(\"Processes used: Main + $(length(workers())) workers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PERFORMANCE SUMMARY & ANALYSIS\n",
    "# =============================================================================\n",
    "println(\"\\n\" * \"=\" ^ 40)\n",
    "println(\"PERFORMANCE SUMMARY\")\n",
    "println(\"=\" ^ 40)\n",
    "println(\"Serial time:          $(round(serial_result.time, digits=3)) seconds\")\n",
    "println(\"Simple distributed:   $(round(mean(simple_times), digits=3)) seconds\")\n",
    "println(\"Chunked distributed:  $(round(mean(chunked_times), digits=3)) seconds\")\n",
    "println()\n",
    "println(\"Speedup (simple):     $(round(serial_result.time / mean(simple_times), digits=2))x\")\n",
    "println(\"Speedup (chunked):    $(round(serial_result.time / mean(chunked_times), digits=2))x\")\n",
    "println(\"Efficiency (simple):  $(round(100 * serial_result.time / (mean(simple_times) * nprocs()), digits=1))%\")\n",
    "println(\"Efficiency (chunked): $(round(100 * serial_result.time / (mean(chunked_times) * nprocs()), digits=1))%\")\n",
    "\n",
    "# Accuracy check\n",
    "println(\"\\nACCURACY CHECK\")\n",
    "println(\"-\" ^ 20)\n",
    "expected = serial_result.value\n",
    "println(\"Expected result:      $expected\")\n",
    "println(\"Serial result:        $(serial_result.value) ✓\")\n",
    "println(\"Simple results:       $(simple_results) $(all(r ≈ expected for r in simple_results) ? \"✓\" : \"✗\")\")\n",
    "println(\"Chunked results:      $(chunked_results) $(all(r ≈ expected for r in chunked_results) ? \"✓\" : \"✗\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed vs Multithreading Comparison\n",
    "\n",
    "### Distributed Computing ✅\n",
    "- **Separate memory spaces** (no shared memory issues)\n",
    "- **Scalable across machines** (can use cluster resources)\n",
    "- **Fault tolerant** (process failure doesn't crash others)\n",
    "- **Better for large-scale, independent computations**\n",
    "- ❌ Higher communication overhead\n",
    "- ❌ More complex data sharing\n",
    "\n",
    "### Multithreading ✅  \n",
    "- **Lower overhead** for shared memory access\n",
    "- **Faster communication** between threads\n",
    "- **Better for fine-grained parallelism**\n",
    "- ❌ Limited to single machine\n",
    "- ❌ Potential race conditions with shared data\n",
    "- ❌ One thread crash can affect the whole process\n",
    "\n",
    "### When to Choose Each\n",
    "- **Use Distributed**: Large datasets, independent tasks, cluster computing\n",
    "- **Use Multithreading**: Shared memory algorithms, fine-grained parallelism, single machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# KEY TAKEAWAYS\n",
    "# =============================================================================\n",
    "println(\"\\n\" * \"=\" ^ 40)\n",
    "println(\"KEY TAKEAWAYS\")\n",
    "println(\"=\" ^ 40)\n",
    "println(\"1. Distributed computing is ideal for large-scale, independent tasks\")\n",
    "println(\"2. Use @distributed for simple cases, pmap for more control\")\n",
    "println(\"3. Chunking reduces communication overhead and improves efficiency\")\n",
    "println(\"4. Consider communication costs vs computation costs\")\n",
    "println(\"5. Distributed computing scales beyond single-machine limitations\")\n",
    "println(\"6. Always verify correctness across all processes\")\n",
    "println()\n",
    "println(\"To add more processes: julia -p N script.jl or addprocs(N)\")\n",
    "\n",
    "# Clean up worker processes (optional - good practice)\n",
    "println(\"\\nCleaning up worker processes...\")\n",
    "rmprocs(workers())\n",
    "println(\"✓ Worker processes removed\")\n",
    "println(\"Current processes: $(nprocs())\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
