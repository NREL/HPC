{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d89e5c97",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Julia Parallel Computing\n",
    "\n",
    "1. Asynchronous Tasks\n",
    "2. Multi-Threading\n",
    "3. Distributed Computing with Distributed.jl\n",
    "4. Distributed Computing with MPI.jl\n",
    "4. GPU Computing (available packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a4552",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will make use of the following basic Monte Carlo integration function through out this presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b002f9fd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using Statistics\n",
    "using BenchmarkTools # for the `@btime` macro\n",
    "\n",
    "function mc_integrate(f::Function, a::Real=0, b::Real=1, n::Int=100000)\n",
    "    ihat = 0.0\n",
    "    for k in 1:n\n",
    "        x = (b - a)*rand() + a\n",
    "        ihat += (f(x) - ihat) / k\n",
    "    end\n",
    "    return ihat\n",
    "end\n",
    "\n",
    "function intense_computation(t::Real)\n",
    "    sleep(t)\n",
    "    return rand()\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ffedf4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tasks\n",
    "\n",
    "1. What are Tasks?\n",
    "2. Creating and Running Tasks\n",
    "3. Communication Between Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359107ad",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What are Tasks?\n",
    "\n",
    "**Tasks** are execution streams that do not depend on each other and can be done in any order. They can be executed asynchronously but they are not executed in parallel. That is, only one task is running at a given time but the order of execution is not predetermined.\n",
    "\n",
    "Tasks are also known as **coroutines**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f79f664",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Creating and Running Tasks\n",
    "\n",
    "Running a task is done in 3 steps:\n",
    "1. Creation\n",
    "2. Scheduling\n",
    "3. Collect Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca13179",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Creating and Running Tasks\n",
    "\n",
    "Creating a task can be done directly with the `Task` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0adc4f4e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (runnable) @0x00000001136e97b0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_task = Task(()->mc_integrate(sin, -pi, pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a446c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note the `Task` constructor takes a function with no arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c11fe2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can always define an zero argument anonymous function to pass to the `Task` constructor. The `@task` macro exists for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8e7849",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (runnable) @0x0000000133a55660"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_task = @task mc_integrate(sin, -pi, pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75bfbf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Creating and Running Tasks\n",
    "\n",
    "Next we schedule the task to run using the `schedule` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07edf4fa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x0000000133a55660"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule(my_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc96af2a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Many times we want to create and schedule a task immediately. We can do this with the `@async` macro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1995b7aa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x0000000112f3a8c0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_task = @async mc_integrate(sin, -pi, pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecce48cb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Creating and Running Tasks\n",
    "\n",
    "We can collect the results of the task once it has completed with the `fetch` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "685622b7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002668053796949929"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch(my_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9574f1d2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are a few helpful details to know about `fetch`:\n",
    "1. If the task has not finished when `fetch` is called, the call to `fetch` will block until the task has completed.\n",
    "2. If the task raises an exception, `fetch` will raise a `TaskFailedException` which wraps the original exception."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066ec16c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Creating and Running Tasks\n",
    "\n",
    "Remember that tasks are not inherently parallel, just asynchronous execution streams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b5de7bd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function run_mci()\n",
    "    N = 10\n",
    "    result = zeros(N)\n",
    "    for k in 1:N\n",
    "        result[k] = mc_integrate(sin, -pi, pi)\n",
    "    end\n",
    "    return mean(result)\n",
    "end\n",
    "\n",
    "function run_mci_task()\n",
    "    N = 10\n",
    "    task_res = zeros(N)\n",
    "    @sync for k in 1:N\n",
    "        @async(task_res[k] = mc_integrate(sin, -pi, pi))\n",
    "    end\n",
    "    return mean(task_res)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed9902c4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  19.574 ms (1 allocation: 144 bytes)\n",
      "  19.532 ms (74 allocations: 5.52 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime run_mci()\n",
    "@btime run_mci_task();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb51e6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**NOTE:** The `@sync` macro will block at the end of the code block until all inclosed `@async` statements have completed execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf775763",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Communicating Between Tasks\n",
    "\n",
    "Sometimes we need to communicate between tasks. An easy way to accomplish this is to use Julia's `Channel` type. We can think of a `Channel` like a pipe or a queue: objects are put in at one end and taken off at the other.\n",
    "\n",
    "Let's rewrite `run_mci_task` to use channels by dividing the `run_mci` workflow into two functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207225d0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Communicating Between Tasks\n",
    "\n",
    "The first function will perform small Monte-Carlo integrations and put the results on a channel with the `put!` function. When it has finished the requested number of computations it will close the channel with `close` and return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c275346",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function integrator(output::Channel{Float64}, N::Int)\n",
    "    for k in 1:N\n",
    "        result = mc_integrate(sin, -pi, pi)\n",
    "        put!(output, result)\n",
    "    end\n",
    "    close(output)\n",
    "    return\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b415825f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**NOTE:** If the channel is full, `put!` will block until space opens up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd4406d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Communicating Between Tasks\n",
    "\n",
    "The second function will take the results off the channel using the `take!` function and accumulate them into an average. We keep pulling results from the channel as long as there is a result or the channel is open. We can check the former with `isready` and the latter with `isopen`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbdfd3ce",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function accumulator(input::Channel{Float64})\n",
    "    mean_val = 0.0\n",
    "    k = 0\n",
    "    while isready(input) || isopen(input)\n",
    "        value = take!(input)\n",
    "        k += 1\n",
    "        mean_val += (value - mean_val) / k\n",
    "    end\n",
    "    return mean_val\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df35bf2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**NOTE:** If the channel is empty, the `take!` function will block until there is an item available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0fe12",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Communicating Between Tasks\n",
    "\n",
    "Now we create channel which can hold 10 results, create and schedule both tasks and finally fetch the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89c39bf8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function run_mci_chan()\n",
    "    comm_ch = Channel{Float64}(10)\n",
    "    atask = @async accumulator(comm_ch)\n",
    "    @async integrator(comm_ch, 10)\n",
    "    result = fetch(atask)    \n",
    "    return result\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f3c4456",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  19.583 ms (24 allocations: 1.72 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime run_mci_chan();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217dca8c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why Tasks?\n",
    "\n",
    "If tasks aren't parallel, why are we talking about them in a parallel computing tutorial?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06379906",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Remeber that tasks are discrete computation units. They naturally define boundaries between computational tasks. Julia's native parallel capabilities are ways of scheduling tasks on other processors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ba0c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multi-Threading\n",
    "\n",
    "1. Starting Julia with Multiple Threads\n",
    "1. `@threads` Macro\n",
    "1. `@spawn` Macro\n",
    "1. Using Channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefdcd57",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Starting Julia with Multiple Threads\n",
    "\n",
    "Julia (v1.3 or greater) has multithreading built into the language. By default, Julia starts with a single thread.  To start Julia with multiple threads either\n",
    "* set the environment variable `JULIA_NUM_THREADS` to some value > 1\n",
    "* start Julia with `--threads` or `-t` option (Julia v1.5 or greater)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedeb0a2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Once started, we can see how many threads are running with the function `Threads.nthreads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3efff6a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4b9197",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `@threads` Macro\n",
    "\n",
    "Many computations take the form of looping over an array where the result of the computation is put into an element in the array and these computations do not interact. In this case, we can make use of the `Threads.@threads` macro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb0482b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lets apply this to our Monte-Carlo integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68ba0844",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function run_mci_mt()\n",
    "    N = 10\n",
    "    mt_res = zeros(N)\n",
    "    Threads.@threads for k in 1:N\n",
    "        mt_res[k] = mc_integrate(sin, -pi, pi)\n",
    "    end\n",
    "    return mean(mt_res)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2db18e16",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.824 ms (14 allocations: 1.14 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime run_mci_mt();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9dc877",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `@spawn` Macro\n",
    "\n",
    "Some applications require dispatching individual tasks on different threads. We can do this using the `Threads.@spawn` macro. This is like the `@async` macro but will schedule the task on an available thread. That is, it creates a `Task` and schedules it but on an available thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aef6883",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function run_mci_mt2()\n",
    "    N = 10\n",
    "    mt_res = Vector{Float64}(undef, N)\n",
    "    @sync for k in 1:N\n",
    "        @async(mt_res[k] = fetch(Threads.@spawn mc_integrate(sin, -pi, pi)))\n",
    "    end\n",
    "    return mean(mt_res)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a6cbd55",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.946 ms (124 allocations: 9.89 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime run_mci_mt2();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1bbf4c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are a couple of oddities about Julia's multi-threading capability to remember:\n",
    "1. An available thread is any thread that has completed all assigned tasks or any remaining tasks are *blocked*.\n",
    "2. As of Julia 1.6, once a task has been assigned to a thread, it remains on that thread even after blocking operations. This will likely change in future releases of Julia.\n",
    "\n",
    "The combination of these two behaviors can lead to load imbalances amongst threads when there are blocking operations within a thread's tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169e291c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Using Channels\n",
    "\n",
    "Just as before, we can use a `Channel` to communicate between tasks in a multi-threaded environment. The only difference is that we replace `@async` with `Threads.@spawn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ca5220d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function run_mci_mt3()\n",
    "    comm_ch = Channel{Float64}(10)\n",
    "    itask = Threads.@spawn integrator(comm_ch, 10)\n",
    "    atask = Threads.@spawn accumulator(comm_ch)\n",
    "    result = fetch(atask)\n",
    "    return result\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d421c85",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "TaskFailedException\n\n\u001b[91m    nested task error: \u001b[39mInvalidStateException: Channel is closed.\n    Stacktrace:\n     [1] \u001b[0m\u001b[1mtry_yieldto\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mundo\u001b[39m::\u001b[0mtypeof(Base.ensure_rescheduled)\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mtask.jl:871\u001b[24m\u001b[39m\n     [2] \u001b[0m\u001b[1mwait\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mtask.jl:931\u001b[24m\u001b[39m\n     [3] \u001b[0m\u001b[1mwait\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mc\u001b[39m::\u001b[0mBase.GenericCondition\u001b[90m{ReentrantLock}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mcondition.jl:124\u001b[24m\u001b[39m\n     [4] \u001b[0m\u001b[1mtake_buffered\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mc\u001b[39m::\u001b[0mChannel\u001b[90m{Float64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mchannels.jl:416\u001b[24m\u001b[39m\n     [5] \u001b[0m\u001b[1mtake!\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mchannels.jl:410\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [6] \u001b[0m\u001b[1maccumulator\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minput\u001b[39m::\u001b[0mChannel\u001b[90m{Float64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[10]:5\u001b[24m\u001b[39m\n     [7] \u001b[0m\u001b[1m(::var\"#21#23\"{Channel{Float64}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mthreadingconstructs.jl:258\u001b[24m\u001b[39m",
     "output_type": "error",
     "traceback": [
      "TaskFailedException\n\n\u001b[91m    nested task error: \u001b[39mInvalidStateException: Channel is closed.\n    Stacktrace:\n     [1] \u001b[0m\u001b[1mtry_yieldto\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mundo\u001b[39m::\u001b[0mtypeof(Base.ensure_rescheduled)\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mtask.jl:871\u001b[24m\u001b[39m\n     [2] \u001b[0m\u001b[1mwait\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mtask.jl:931\u001b[24m\u001b[39m\n     [3] \u001b[0m\u001b[1mwait\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mc\u001b[39m::\u001b[0mBase.GenericCondition\u001b[90m{ReentrantLock}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mcondition.jl:124\u001b[24m\u001b[39m\n     [4] \u001b[0m\u001b[1mtake_buffered\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mc\u001b[39m::\u001b[0mChannel\u001b[90m{Float64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mchannels.jl:416\u001b[24m\u001b[39m\n     [5] \u001b[0m\u001b[1mtake!\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mchannels.jl:410\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [6] \u001b[0m\u001b[1maccumulator\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minput\u001b[39m::\u001b[0mChannel\u001b[90m{Float64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[10]:5\u001b[24m\u001b[39m\n     [7] \u001b[0m\u001b[1m(::var\"#21#23\"{Channel{Float64}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mthreadingconstructs.jl:258\u001b[24m\u001b[39m",
      "",
      "Stacktrace:",
      "  [1] wait",
      "    @ ./task.jl:345 [inlined]",
      "  [2] fetch",
      "    @ ./task.jl:360 [inlined]",
      "  [3] run_mci_mt3()",
      "    @ Main ./In[18]:5",
      "  [4] var\"##core#408\"()",
      "    @ Main ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:489",
      "  [5] var\"##sample#409\"(::Tuple{}, __params::BenchmarkTools.Parameters)",
      "    @ Main ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:497",
      "  [6] _lineartrial(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters; maxevals::Int64, kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:161",
      "  [7] _lineartrial(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters)",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:152",
      "  [8] #invokelatest#2",
      "    @ ./essentials.jl:729 [inlined]",
      "  [9] invokelatest",
      "    @ ./essentials.jl:726 [inlined]",
      " [10] #lineartrial#46",
      "    @ ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:35 [inlined]",
      " [11] lineartrial",
      "    @ ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:35 [inlined]",
      " [12] tune!(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters; progressid::Nothing, nleaves::Float64, ndone::Float64, verbose::Bool, pad::String, kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:251",
      " [13] tune! (repeats 2 times)",
      "    @ ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:247 [inlined]",
      " [14] top-level scope",
      "    @ ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:576",
      " [15] eval",
      "    @ ./boot.jl:368 [inlined]",
      " [16] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "@btime run_mci_mt3();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315dfa9f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**NOTE:** We can see from the timing results this is not the best way to distribute the work since the `integrator` function has much more computational work than the `accumulator` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7770087",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Distributed Computing with Distributed.jl\n",
    "\n",
    "1. Architecture\n",
    "1. Setting Up\n",
    "1. `@distributed` Macro\n",
    "1. `@spawnat` Macro\n",
    "1. Remote Channels\n",
    "1. Shutting Down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23450144",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Architecture\n",
    "\n",
    "Communication patterns are one-sided so users only manage one process. Communication itself takes the form of function or macro calls rather than explicit send and receive calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3213d3b5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Distributed.jl is built on two basic types: remote calls and remote references. A remote call is a directive to execute a particular function on a particular process. A remote reference is a reference to a variable stored on a particular process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae482247",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There is a strong resemblence to the way Julia handles tasks: Function calls (wrapped in appropriate types) are scheduled on worker processes through remote calls which return remote references. The results of these calls are then retrieved by fetching the values using the remote references."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e59f3b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Setting Up\n",
    "\n",
    "We can launch more Julia processes on the same or other machines with the `addprocs` function. Here we launch 2 worker processes on the local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82539d4f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using Distributed\n",
    "addprocs(2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5712f2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Each Julia process is identified by a (64-bit) integer. We can get a list of all active processes with `procs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea42ab40",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procs() = [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "@show procs();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89efc02",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There is a distinction between the original Julia process and those we launched. The original Julia process is often called the **master** process and always has id equal to 1. The launched processes are called **workers**. We can obtain a list of workers with the `workers` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53b712fc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workers() = [2, 3]\n"
     ]
    }
   ],
   "source": [
    "@show workers();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b4f95",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By default, distributed processing operations use the workers only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c076423",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Setting Up\n",
    "\n",
    "We can also start up worker processes from the command lines using the `-p` or `--procs` option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1ea323",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In order to launch Julia processes on other machines, we give `addprocs` a vector of tuples where each tuple is the hostname as a string paired with the number of processes to start on that host."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235e863",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Setting Up\n",
    "\n",
    "The Julia global state is not copied in the new processes. We need to manually load any modules and define any functions we need. This is done with the `Distributed.@everywhere` macro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e033fe75",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "@everywhere using Statistics\n",
    "@everywhere function mc_integrate(f::Function, a::Real=0, b::Real=1, n::Int=100000)\n",
    "    ihat = 0.0\n",
    "    for k in 1:n\n",
    "        x = (b - a)*rand() + a\n",
    "        ihat += (f(x) - ihat) / k\n",
    "    end\n",
    "    return ihat\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d864654",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `@distributed` Macro\n",
    "\n",
    "The `@distributed` macro is the distributed memory equivalent of the `Threads.@threads` macro. This macro partitions the range of the for loop and executes the computation on all worker processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8068c3c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function run_mci_dist()\n",
    "    N = 10\n",
    "    total = @distributed (+) for k in 1:N\n",
    "        mc_integrate(sin, -pi, pi)\n",
    "    end\n",
    "    return total/N\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb248c65",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10.065 ms (143 allocations: 6.67 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime run_mci_dist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7347f0e6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Between the macro and the for loop is an optional reduction. Here we have used `+` but this can be any valid reduction operator including a user defined function. The values given to the reduction are the values of the last expression in the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f3c9c2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**NOTE:** If we do not provide a reduction, `@distributed` creates a task for each element of the loop and schedules them on worker processes and returns without waiting for the tasks to complete. To wait for completion of the tasks, the whole block can be wrapped with `@sync` macro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3f5257",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `@spawnat` Macro\n",
    "\n",
    "Julia also provides more fine grained control for launching tasks on workers with the `@spawnat` Macro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f32ec0d1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function run_mci_dist2()\n",
    "    N = 10\n",
    "    futures = Vector{Future}(undef, N)\n",
    "    for k in 1:N\n",
    "        futures[k] = @spawnat(:any, mc_integrate(sin, -pi, pi))\n",
    "    end\n",
    "    return mean(fetch.(futures))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a78b65",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first argument to `@spawnat` is the worker to run the computation on. Here we have used `:any` indicating that Julia should pick a process for us. If we wanted to execute the computation on a particular worker, we could specify which one with the worker id value. The second argument is the expression to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe3268",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`@spawnat` returns a `Future` which is a remote reference. We call `fetch` on it to retrieve the value of the computation. Note that `fetch` will block until the computation is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64123a63",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  11.928 ms (1233 allocations: 52.48 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime run_mci_dist2();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0e67c6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `@spawnat` Macro\n",
    "\n",
    "**WARNING:** The entire expression is sent to the worker process before anything in the expression is executed. This can cause performance issues if we need a small part of a big object or array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f28213b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "@everywhere struct MyData\n",
    "    Data::Vector{Float64}\n",
    "    N::Int\n",
    "end\n",
    "function slow(my_data::MyData)\n",
    "    return fetch(@spawnat(2, mean(rand(my_data.N))))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "155705f5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.740 ms (100 allocations: 4.13 KiB)\n"
     ]
    }
   ],
   "source": [
    "large_data = MyData(rand(1000000), 5)\n",
    "@btime slow(large_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f27704f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `@spawnat` Macro\n",
    "\n",
    "**WARNING:** The entire expression is sent to the worker process before anything in the expression is executed. This can cause performance issues if we need a small part of a big object or array.\n",
    "\n",
    "This is easily fixed using a local variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5df1b86",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function fast(my_data::MyData)\n",
    "    n = my_data.N\n",
    "    return fetch(@spawnat(2, mean(rand(n))))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9218427f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  164.427 μs (92 allocations: 3.87 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime fast(large_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6ee9908",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "large_data = nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fbd1d5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**TODO:** Do I want to do this bit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe4311b5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_mci_dist3 (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function run_mci_dist3()\n",
    "    N = 10\n",
    "    vals = Vector{Float64}(undef, N)\n",
    "    @sync for k in 1:N\n",
    "        @async(vals[k] = @fetch(mc_integrate(sin, -pi, pi)))\n",
    "    end\n",
    "    return mean(vals)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5dd77a5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10.536 ms (605 allocations: 29.14 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime run_mci_dist3();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "553e1760",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_mci_dist4 (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SharedArrays\n",
    "function run_mci_dist4()\n",
    "    N = 10\n",
    "    vals = SharedArray{Float64}(N)\n",
    "    @sync @distributed for k in 1:N\n",
    "        vals[k] = mc_integrate(sin, -pi, pi)\n",
    "    end\n",
    "    return mean(vals)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7256201d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10.850 ms (493 allocations: 21.78 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime run_mci_dist4();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d2b009",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Remote Channels\n",
    "\n",
    "As suggested by the name, these are the remote versions of the `Channel` type we've already seen. If you look at the source code, they are actually wrap an `AbstractChannel` to provide the needed remote functionality. We can effectively treat them just like a `Channel`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eed678a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's redo our our `integrator` - `accumulator` workflow but this time let's do a better job of distributing the work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c274e1e9",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "@everywhere function integrator(output::RemoteChannel{Channel{Float64}}, N::Int)\n",
    "    for k in 1:N\n",
    "        result = mc_integrate(sin, -pi, pi)\n",
    "        put!(output, result)\n",
    "    end\n",
    "    put!(output, NaN)\n",
    "    return\n",
    "end;\n",
    "@everywhere function accumulator(input::RemoteChannel{Channel{Float64}}, nworkers::Int)\n",
    "    mean_val = 0.0\n",
    "    k = 0\n",
    "    finished = 0\n",
    "    while finished < nworkers\n",
    "        value = take!(input)\n",
    "        if value === NaN\n",
    "            finished += 1\n",
    "        else\n",
    "            k += 1\n",
    "            mean_val += (value - mean_val) / k\n",
    "        end\n",
    "    end\n",
    "    return mean_val\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26f02e9a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function run_mci_rc()\n",
    "    comm_ch = RemoteChannel(()->Channel{Float64}(10), 1)\n",
    "    @spawnat(2, integrator(comm_ch, 5))\n",
    "    @spawnat(3, integrator(comm_ch, 5))\n",
    "    atask = @async accumulator(comm_ch, nworkers())\n",
    "    return fetch(atask)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023a8214",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here we create a `RemoteChannel` on the master process, divide the computationally intensive `integrator` function into two calls and remotely execute them on the worker processes. Then we start a task on the master process to accumulate the values and call fetch to wait for and retrieve the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "796624fd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  11.281 ms (1130 allocations: 46.59 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime run_mci_rc();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bcbcf5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Shutting Down\n",
    "\n",
    "To shutdown the worker processes we can use `rmprocs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b93bf17",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x0000000112924010"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmprocs(workers())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76360bb0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Alternatively, we can also just exit Julia and the workers will be shutdown as part of the exit process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d5080c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Distributed Computing with MPI.jl\n",
    "\n",
    "1. Overview of MPI.jl\n",
    "1. Example\n",
    "\n",
    "<!-- **TODO:** Stuff:\n",
    "1. Outline\n",
    "2. describe MPI.jl api and capabilities\n",
    "2. breakup script\n",
    "3. describe what we're doing -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b7ac61",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overview of MPI.jl\n",
    "\n",
    "[MPI.jl](https://github.com/JuliaParallel/MPI.jl) is a Julia wrapper around an MPI library. By default it will download an MPI library suitable for running on the installing system. However, it is easily configured to use an existing system MPI implementation (e.g. one of the MPI modules on Eagle). See the documentation for [instructions on how to do this](https://juliaparallel.github.io/MPI.jl/stable/configuration/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932c7c9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "MPI.jl mostly requires transmitted things to be buffers of basic types (types that are easily converted to C). Some functions can transmit arbitrary data by serializing them but this functionality is not as fleshed out as in mpi4py."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0146fe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "We first need to load and initialize MPI.\n",
    "\n",
    "```julia\n",
    "using MPI\n",
    "MPI.Init()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707967eb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`MPI.Init` loads the MPI library and calls `MPI_Init` as well as sets up types for that specific MPI library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1aedd7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "Now we can implement our Monte-Carlo integration workflow using MPI\n",
    "\n",
    "```julia\n",
    "function run_mci_mpi()\n",
    "\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = MPI.Comm_rank(comm)\n",
    "    size = MPI.Comm_size(comm)\n",
    "\n",
    "    if rank == 0\n",
    "        N = 10\n",
    "        num = [N]\n",
    "    else\n",
    "        num = Vector{Int}(undef, 1)\n",
    "    end\n",
    "    MPI.Bcast!(num, 0, comm)\n",
    "\n",
    "    rank_sum = 0.0\n",
    "    for k in rank+1:size:num[1]\n",
    "        rank_sum += mc_integrate(sin, -pi, pi)\n",
    "    end\n",
    "\n",
    "    total = MPI.Reduce([rank_sum], MPI.SUM, 0, comm)\n",
    "    if rank == 0\n",
    "        result = total / N\n",
    "    else\n",
    "        result = nothing\n",
    "    end\n",
    "\n",
    "    return result\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec9dbf4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "To benchmark this we time it many (10000) times and track the minimal value (this is similar to what the `@btime` macro does).\n",
    "\n",
    "```julia\n",
    "function run_loop(nruns::Int)\n",
    "    \n",
    "    min_time = 1e10\n",
    "    result = 0.0\n",
    "    \n",
    "    for _ in 1:nruns\n",
    "        MPI.Barrier(MPI.COMM_WORLD)\n",
    "        start = time()\n",
    "        result = run_mci_mpi()\n",
    "        stop = time()\n",
    "        elapsed = stop - start\n",
    "        if elapsed < min_time\n",
    "            min_time = elapsed\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if MPI.Comm_rank(MPI.COMM_WORLD) == 0\n",
    "        println(\"Elapsed time: \", min_time)\n",
    "    end\n",
    "\n",
    "    return\n",
    "end\n",
    "\n",
    "run_loop(10000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1517644",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "Results\n",
    "\n",
    "```shell\n",
    "mpirun -n 2 julia mpi_mci.jl\n",
    "  Activating environment at `~/HPC_Apps/julia-tutorial/Project.toml`\n",
    "  Activating environment at `~/HPC_Apps/julia-tutorial/Project.toml`\n",
    "Elapsed time: 0.01108694076538086\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08380f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GPU Computing\n",
    "\n",
    "We provide a brief survey of available packages that can be used to get started.\n",
    "\n",
    "Packages exist for [NVIDIA's CUDA](https://github.com/JuliaGPU/CUDA.jl), [AMD's ROCm](https://github.com/JuliaGPU/AMDGPU.jl), and [Intel's oneAPI](https://github.com/JuliaGPU/oneAPI.jl). CUDA.jl is the most mature while the other two, as of this writing, are still underdevelopment.\n",
    "\n",
    "The package [KernelAbstractions.jl](https://github.com/JuliaGPU/KernelAbstractions.jl) is an abstraction layer for enabling different GPU backends.\n",
    "\n",
    "See the JuliaGPU organization's [webpage](https://juliagpu.org/) or [github repo](https://github.com/JuliaGPU) for a great place to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e504df2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Additional Resources\n",
    "\n",
    "The following are great resource for learning more\n",
    "\n",
    "*  [Julia Documentation](https://docs.julialang.org/en/v1/) -- the manual discusses the inner workings of Julia including the native parallel computing capabilities\n",
    "*  [Julia community](https://julialang.org/community/) especially the following discourse channels\n",
    "    - [Julia discourse](https://discourse.julialang.org/) -- all channels\n",
    "    - [Julia at Scale discourse](https://discourse.julialang.org/c/domain/parallel/34) -- for scalable Julia\n",
    "    - [Julia GPU discourse](https://discourse.julialang.org/c/domain/gpu/11) -- for GPU Julia computing\n",
    "*  [Julia Youtube Channel](https://www.youtube.com/c/TheJuliaLanguage) -- tutorials for Julia and Julia packages\n",
    "*  MPI.jl [package repo](https://github.com/JuliaParallel/MPI.jl) and [documentation](https://juliaparallel.github.io/MPI.jl/stable/)\n",
    "*  JuliaGPU [webpage](https://juliagpu.org/) and [github repo](https://github.com/JuliaGPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad37eb",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia-T2 1.8.1",
   "language": "julia",
   "name": "julia-t2-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
